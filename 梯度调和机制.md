### Gradient Harmonized Single-stage Detector
- 核心思想：对样本的梯度进行统计，根据梯度分布设计了梯度均衡机制，嵌入在loss函数中，用于改善训练过程

本文是发表在AAAI2019上的Oral论文，由香港中文大学王小刚团队完成，用于解决在单阶段目标检测（one stage object detection）中面临的样本分布不均衡的问题。样本分布不均衡主要表现在，正负样本的个数(postive, negative), 以及简单样本与困难样本(easy, hard)之间的在数量的巨大差异，众所周知，在单目标检测上，往往会生成 $ 10^5到10^6$的候选框，为了高效的进行计算，仅仅选取部分窗口进行loss计算。

作者从梯度的分布上来看待样本的难易分布，通过利用**梯度密度**系数来调节分类问题中的交叉熵损失函数来动态的修正权重，使得简单样本与困难样本都能对梯度有均匀的贡献。

#### 问题描述

以二分类为例，对于一个候选框，定义模型预测的概率为$p,  p \in [0, 1]$, 真实标签定义为 $p^*, p^* \in \{0, 1\}$。对于交叉熵损失：

$$L_{CE}(p, p^*) = 
\begin{cases}
 -log(p) &  p^*=1 \\
 -log(1-p) & p^*=0
\end{cases}
$$
假定$x$为模型最后一层的输出，在神经网络中，对于二分类问题，常利用$p = sigmod(x)$作为激活函数，得到最终的预测概率，那么关于$x$的梯度可以推出:

$$\frac{\partial L_{CE}}{\partial x} = 
\begin{cases}
p - 1 & p^*=1 \\
p & p^*=0
\end{cases} \\
= p - p^*
$$
所以，梯度的模为：
$$
g = |p - p^*| = \begin{cases}
1 - p & p^* = 1 \\
p & p^*=0
\end{cases}
$$

> 通过上述的公式发现, 每个样本对模型训练的作用在于产生一个梯度用于更新模型参数，不同样本的贡献存在差异

由上述梯度的模的公式可见， 梯度的模可以反映出一个样本对于最终的贡献程度，当模型能够正确区分样本时，梯度的模会很小，当模型产生错误分类时，梯度的模会很大。因此，梯度的模能够体现出一个样本的困难程度。
在实际的模型中， 往往是简单样本占据总样本的绝大多数，如目标检测中背景是很容易进行区分的，也是占据图像区域的绝大部分面积，所以这些easy, negative样本产生的梯度累加贡献会占主导作用，此外，一些hard的样本也会对梯度贡献很大， 在这样的梯度贡献不均匀的情况下， 最终造成模型得不到充分的训练。

- 设计新的loss函数，抑制大量的简单样本对模型的影响
##### 梯度推导过程
当$p^*=1$ 时
$$
\frac{\partial L_{CE}}{\partial x} = {[-log(p)]}^{'} \\
= {[-log(\frac{1}{1 + e^{-x}})]}^{'} \\
=  {[log({1 + e^{-x}})]}^{'} \\
= \frac{-e^{-x}}{1 + e^{-x}} \\
= \frac{1 - (e^{-x} + 1)}{1 + e^{-x}} \\
= \frac{1}{1 + e^{-x}} - 1\\
= p -1
$$

当$p^*=0$ 时
$$
\frac{\partial L_{CE}}{\partial x} = {[-log(1- p)]}^{'} \\
= {[-log(1 - \frac{1}{1 + e^{-x}})]}^{'} \\
= {[-log(\frac{e^{-x}}{1 + e^{-x}})]}^{'} \\
= {[-loge^{-x} + log(1 + e^{-x})]}^{'} \\
= {[x + log(1 + e^{-x})]}^{'} \\
= 1 + \frac{-e^{-x}}{1 + e^{-x}} \\
= p
$$

#### 梯度密度-Gradient Density
##### 原始定义-时间复杂度为$O(N^2)$
如果物质的密度表示单位体积下的物体质量一样，**梯度密度用于表示单位梯度取值范围内包含的样本个数**。对于原始的计算过程，分为下面几个步骤：

- 分布按照上述的公式计算各个样本的梯度的模，时间复杂度为 $O(N)$
- 对梯度的模进行排序， 最快的排序算法下，时间复杂度为 $O(NlogN)$
- 为每个样本计算在容许的范围内$\varepsilon$，有多少个样本的梯度的模是以$g$为中心，落在其周围

$$
GD(g) = \frac{1}{l_\varepsilon}\sum_{k=1}^{N}\delta(g_k, g)
$$
其中$g_k表示的是第k个样本的梯度的模， \delta(x, y)为阶跃函数$
$$
\delta(x, y) = 
\begin{cases}
1 & if \quad  y-\frac{\varepsilon}{2} \leq x < y + \frac{\varepsilon}{2} \\
0 & otherwise
\end{cases}
$$
最终得到每个样本的梯度修正因子，用于加权交叉熵损失函数
$$
修正因子： \beta_i = \frac{N}{GD(g_i)}
$$


$$
加权交叉熵损失：L_{GHM-C} 
= \frac{1}{N}\sum_{i=1}^{N}\beta_iL_{CE}(p_i, p^*) \\
= \sum_{i=1}^{N} \frac{L_{CE}(p_i, p^*)}{GD(g_i)}
$$



> - 如果梯度的模$g_i$周围存在很多这样的样本, 那么在训练过程中需要进行降权，$\beta_i$的取值就要变小，反之亦然
> - 为什么$\beta_i$的分子需要为$N$,而不是$1$呢？ 想象一下，如果所有的样本模都是相同的，那么$GD(g_i) = N$, 最终$\beta_i = 1$， 这样就不会影响最终的损失函数


##### 近似计算-时间复杂度为$O(MN)$
然而上述梯度密度的定义，时间复杂度太高，需要进行近似计算,使得时间复杂度为$O(MN)$，**离散化： 梯度的模的直方图**，总结为：
> 将总体样本的梯度的模$g$划分从$M$等份（每份的长度为$\varepsilon = \frac{1}{M}$，$ind_{(g)}=1, 2, 3, ...M$） ，分别统计落入各个$bin$内的样本个数，记为$R_{ind_(g)}$, ，那么梯度的密度为
> $$
> \hat{GD}(g) =  \frac{R_{ind_(g)}}{\varepsilon} = R_{ind_(g)}M
> $$
> $$
>修正因子：\hat{\beta_i} = \frac{N}{\hat{GD}(g_i)}
>$$
>$$
>加权交叉熵损失： L_{GHM-C} 
>= \frac{1}{N}\sum_{i=1}^{N}\hat{\beta_i}L_{CE}(p_i, p^*) \\
>= \sum_{i=1}^{N} \frac{L_{CE}(p_i, p^*)}{\hat{GD}(g_i)}
>$$


#### 代码实现

- 细节：样本统计使用指数滑动加权平均
考虑到网络在训练过程中是以 min-batch的形式将数据输入到网络，为了消除数据抽样带来的噪音以及可能引起的训练不稳定性，引入EMA（Exponential moving average），指数滑动加权平均对梯度密度进行计算: 首先对于落入各个区间的样本个数进行更新
$$
S_{j}^{(t)} = \alpha S_{j}^{(t-1)}  + (1 - \alpha)R_{j}^{t-1}
$$
利用$S_{j}^{(t)} $代替当前计算出来的样本个数
$$
\hat{GD}(g) = \frac{S_{ind_(g)}}{\varepsilon} = S_{ind_(g)}M
$$
- 具体代码：[GHM_Detection](https://github.com/libuyu/GHM_Detection/blob/master/mmdetection/mmdet/core/loss/ghm_loss.py)

```python
import torch
import torch.nn.functional as F


class GHMC_Loss:
    def __init__(self, bins=10, momentum=0):
        self.bins = bins
        self.momentum = momentum
        self.edges = [float(x) / bins for x in range(bins+1)]
        self.edges[-1] += 1e-6
        if momentum > 0:
            self.acc_sum = [0.0 for _ in range(bins)]

    def calc(self, input, target, mask):
        """ Args:
        input [batch_num, class_num]:
            The direct prediction of classification fc layer.
        target [batch_num, class_num]:
            Binary target (0 or 1) for each sample each class. The value is -1
            when the sample is ignored.
        """
        edges = self.edges
        mmt = self.momentum
        weights = torch.zeros_like(input)

        # gradient length
        g = torch.abs(input.sigmoid().detach() - target)

        valid = mask > 0
        tot = max(valid.float().sum().item(), 1.0)
        n = 0  # n valid bins
        for i in range(self.bins):
            inds = (g >= edges[i]) & (g < edges[i+1]) & valid
            num_in_bin = inds.sum().item()
            if num_in_bin > 0:
                if mmt > 0:
                    self.acc_sum[i] = mmt * self.acc_sum[i] \
                        + (1 - mmt) * num_in_bin
                    weights[inds] = tot / self.acc_sum[i]
                else:
                    weights[inds] = tot / num_in_bin
                n += 1
        if n > 0:
            weights = weights / n

        loss = F.binary_cross_entropy_with_logits(
            input, target, weights, reduction='sum') / tot
        return loss

```